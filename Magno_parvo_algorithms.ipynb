{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nelsonalbertohj/Magno-Parvo-CNN/blob/main/Magno_parvo_algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "B8jN2PimUzk6",
        "outputId": "74401541-451d-425e-b773-717db8a0febc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "B8jN2PimUzk6",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "273e5c47",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "273e5c47",
        "outputId": "3baaca17-5d04-4656-ef3c-cae6eff513ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version:  2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Average\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_addons as tfa\n",
        "print(\"Tensorflow version: \",tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTxP_p0fZrGX",
        "outputId": "34908809-1f32-4c33-de84-78b384d22668"
      },
      "id": "FTxP_p0fZrGX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "61f265cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61f265cf",
        "outputId": "7aeda48a-5da3-4ad0-c2d7-1a579ccecdb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 60058 files belonging to 50 classes.\n",
            "Using 48047 files for training.\n",
            "Found 60058 files belonging to 50 classes.\n",
            "Using 12011 files for validation.\n"
          ]
        }
      ],
      "source": [
        "loc = \"/content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Imagenet-50-1500-splits/train\"\n",
        "data_dir = pathlib.Path(loc)\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "#Training set\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  label_mode = 'categorical',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "#Testing set\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  label_mode = 'categorical',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "498b8dd1",
      "metadata": {
        "id": "498b8dd1"
      },
      "outputs": [],
      "source": [
        "def img_transforms(data,label):\n",
        "    normalize_img = tf.keras.layers.Rescaling(1./255)\n",
        "    color_norm = normalize_img(data)\n",
        "    gray_img = tf.image.rgb_to_grayscale(data)\n",
        "    gray_norm_img = normalize_img(gray_img)\n",
        "    gray_norm_img = tfa.image.gaussian_filter2d(gray_norm_img,filter_shape=(10,10),sigma=5.0)\n",
        "    concat_img = tf.concat([color_norm, gray_norm_img],axis=-1)\n",
        "    return concat_img,label\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds_preprocessed = train_ds.map(img_transforms)\n",
        "val_ds_preprocessed = val_ds.map(img_transforms)\n",
        "\n",
        "#NOTE: THE CASHE ON DISK IS ONLY NECESSARY IF HAVING ISSUES WITH IMAGE LOADING BOTTLENECK\n",
        "CASHE_Train = \"/content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Imagenet-50-1500-splits/CASHE_Train_Blur_50_1500\"\n",
        "CASHE_Val = \"/content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Imagenet-50-1500-splits/CASHE_Val_Blur_50_1500\"\n",
        "train_ds_preprocessed = train_ds_preprocessed.cache(CASHE_Train).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds_preprocessed = val_ds_preprocessed.cache(CASHE_Val).prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to create CASHE in local disk by loading all images\n",
        "idx = 0\n",
        "start_time = time.time()\n",
        "for t in train_ds_preprocessed:\n",
        "  print(\"time to get object: \", time.time()-start_time)\n",
        "  idx += 1\n",
        "  start_time = time.time()"
      ],
      "metadata": {
        "id": "X7cRFBywFpP8"
      },
      "id": "X7cRFBywFpP8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0265e93d",
      "metadata": {
        "id": "0265e93d"
      },
      "outputs": [],
      "source": [
        "#Visualizing gray images and other effects\n",
        "np.random.seed(0)\n",
        "\n",
        "def img_transforms_no_blur(data,label):\n",
        "    normalize_img = tf.keras.layers.Rescaling(1./255)\n",
        "    color_norm = normalize_img(data)\n",
        "    gray_img = tf.image.rgb_to_grayscale(data)\n",
        "    gray_norm_img = normalize_img(gray_img)\n",
        "    concat_img = tf.concat([color_norm, gray_norm_img],axis=-1)\n",
        "    return concat_img,label\n",
        "\n",
        "val_ds_preprocessed_no_blur = val_ds.map(img_transforms_no_blur)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "gray_imgs = []\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in val_ds_preprocessed_no_blur.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        current_img = images[i]\n",
        "        plt.imshow(current_img.numpy()[:,:,-1],cmap=\"gray\")\n",
        "        gray_imgs.append((current_img,np.argmax(labels[i])))\n",
        "        plt.title(class_names[np.argmax(labels[i])])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, (images, labels) in enumerate(gray_imgs):\n",
        "      ax = plt.subplot(3, 3, i + 1)\n",
        "      blurred_img = tfa.image.gaussian_filter2d(images[:,:,-1:],filter_shape=(10,10),sigma=5.0)\n",
        "      plt.imshow(blurred_img.numpy().squeeze(),cmap=\"gray\")\n",
        "      plt.title(class_names[labels])\n",
        "      plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dual Stream ResNet Architecture"
      ],
      "metadata": {
        "id": "UmSResCstPc0"
      },
      "id": "UmSResCstPc0"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import dropout\n",
        "class DualStream_ResNet(tf.keras.Model):\n",
        "    def __init__(self, n_outputs, batch_size, freeze = True, load_type=None, \n",
        "                 merge_type=\"averaging\"):\n",
        "        super().__init__()\n",
        "        self.n_outputs =  n_outputs\n",
        "        self.merge_type = merge_type\n",
        "\n",
        "        self.magno_stream = tf.keras.applications.ResNet50(\n",
        "                            include_top=False,\n",
        "                            weights= load_type,\n",
        "                            input_tensor=None,\n",
        "                            input_shape=None,\n",
        "                            pooling=None,\n",
        "                            classes=n_outputs,\n",
        "                            )\n",
        "        \n",
        "        self.parvo_stream = tf.keras.applications.ResNet50(\n",
        "                            include_top=False,\n",
        "                            weights= load_type,\n",
        "                            input_tensor=None,\n",
        "                            input_shape=None,\n",
        "                            pooling=None,\n",
        "                            classes=n_outputs,\n",
        "                            )\n",
        "        if freeze:\n",
        "          self.magno_stream.trainable = False\n",
        "          self.parvo_stream.trainable = False\n",
        "\n",
        "        self.flat = tf.keras.layers.Flatten()\n",
        "        self.fc = Sequential([#tf.keras.layers.Dense(2048,activation='ReLU'),\n",
        "                              # tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(1280, activation='ReLU'),\n",
        "                              tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(640, activation='ReLU'),\n",
        "                              tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(self.n_outputs, activation='softmax')])\n",
        "        \n",
        "        self.avg = tf.keras.layers.Average()\n",
        "        self.concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "    def call(self,inputs):\n",
        "        color_input = inputs[:,:,:,:-1]\n",
        "        gray_input = inputs[:,:,:,-1:]\n",
        "        concat_gray_input = tf.concat([gray_input,\n",
        "                                      gray_input,\n",
        "                                      gray_input],axis=-1)\n",
        "\n",
        "        m_stream = self.magno_stream(color_input)\n",
        "        m_stream = self.flat(m_stream)\n",
        "        \n",
        "        p_stream = self.parvo_stream(concat_gray_input)\n",
        "        p_stream = self.flat(p_stream)\n",
        "        \n",
        "        if self.merge_type == \"averaging\":\n",
        "          avg_outputs = self.avg([p_stream,m_stream])\n",
        "        elif self.merge_type == \"concat\":\n",
        "          avg_outputs = self.concat([p_stream,m_stream])\n",
        "        else:\n",
        "          raise \"That layer option is not available\"\n",
        "        return self.fc(avg_outputs)"
      ],
      "metadata": {
        "id": "PVDAyYHHiwX8"
      },
      "id": "PVDAyYHHiwX8",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FREEZE = False \n",
        "LOAD_WEIGHTS = None #One of None or imagenet\n",
        "dual_stream_model = DualStream_ResNet(50,batch_size,FREEZE,load_type=LOAD_WEIGHTS,\n",
        "                                      merge_type=\"averaging\")\n",
        "dual_stream_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "nrmij0NKjg0Z"
      },
      "id": "nrmij0NKjg0Z",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_loc = \"/content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/\"\n",
        "model_name = \"Dualstream_with_ResNet_1000_Samples_Deeper_50Classes\"\n",
        "checkpoint_path = f\"{model_save_loc}{model_name}\"\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 monitor='val_accuracy',\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "train_history = dual_stream_model.fit(train_ds_preprocessed, validation_data= val_ds_preprocessed,\n",
        "                                      epochs= 60, callbacks=[callback,cp_callback], workers = 4)\n",
        "\n",
        "# dual_stream_model.save()\n",
        "\n",
        "#Save training history to CSV\n",
        "hist_df = pd.DataFrame(train_history.history)\n",
        "\n",
        "hist_csv_file = f\"{model_save_loc}{model_name}_history.csv\"\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_history.history['accuracy'])\n",
        "plt.plot(train_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RAojac_FjiHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "outputId": "0cb7c4f2-0c5a-4a1b-8517-dcc634c38be1"
      },
      "id": "RAojac_FjiHf",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "1502/1502 [==============================] - ETA: 0s - loss: 5.0708 - accuracy: 0.0409\n",
            "Epoch 1: saving model to /content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Dualstream_with_ResNet_1000_Samples_Deeper_50Classes\n",
            "1502/1502 [==============================] - 598s 391ms/step - loss: 5.0708 - accuracy: 0.0409 - val_loss: 3.7750 - val_accuracy: 0.0769\n",
            "Epoch 2/60\n",
            "1502/1502 [==============================] - ETA: 0s - loss: 3.3881 - accuracy: 0.1164\n",
            "Epoch 2: saving model to /content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Dualstream_with_ResNet_1000_Samples_Deeper_50Classes\n",
            "1502/1502 [==============================] - 586s 390ms/step - loss: 3.3881 - accuracy: 0.1164 - val_loss: 3.1850 - val_accuracy: 0.1691\n",
            "Epoch 3/60\n",
            "1502/1502 [==============================] - ETA: 0s - loss: 3.0746 - accuracy: 0.1818\n",
            "Epoch 3: saving model to /content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Dualstream_with_ResNet_1000_Samples_Deeper_50Classes\n",
            "1502/1502 [==============================] - 587s 390ms/step - loss: 3.0746 - accuracy: 0.1818 - val_loss: 3.4412 - val_accuracy: 0.1357\n",
            "Epoch 4/60\n",
            "1502/1502 [==============================] - ETA: 0s - loss: 2.9510 - accuracy: 0.2124\n",
            "Epoch 4: saving model to /content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Dualstream_with_ResNet_1000_Samples_Deeper_50Classes\n",
            "1502/1502 [==============================] - 586s 389ms/step - loss: 2.9510 - accuracy: 0.2124 - val_loss: 3.2394 - val_accuracy: 0.1756\n",
            "Epoch 5/60\n",
            "1502/1502 [==============================] - ETA: 0s - loss: 2.8083 - accuracy: 0.2439\n",
            "Epoch 5: saving model to /content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Dualstream_with_ResNet_1000_Samples_Deeper_50Classes\n",
            "1502/1502 [==============================] - 588s 391ms/step - loss: 2.8083 - accuracy: 0.2439 - val_loss: 3.3271 - val_accuracy: 0.1580\n",
            "Epoch 6/60\n",
            "1502/1502 [==============================] - ETA: 0s - loss: 2.6308 - accuracy: 0.2822\n",
            "Epoch 6: saving model to /content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Dualstream_with_ResNet_1000_Samples_Deeper_50Classes\n",
            "1502/1502 [==============================] - 586s 389ms/step - loss: 2.6308 - accuracy: 0.2822 - val_loss: 3.2805 - val_accuracy: 0.1655\n",
            "Epoch 7/60\n",
            " 265/1502 [====>.........................] - ETA: 8:07 - loss: 2.5626 - accuracy: 0.2996"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f5d858239a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m train_history = dual_stream_model.fit(train_ds_preprocessed, validation_data= val_ds_preprocessed,\n\u001b[0;32m---> 11\u001b[0;31m                                       epochs= 60, callbacks=[callback,cp_callback], workers = 4)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# dual_stream_model.save()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Model:\n",
        "dual_stream_model = tf.keras.models.load_model(\"/content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Dualstream_with_ResNet_1000_Samples_Deeper_50Classes\")\n",
        "# eval_loss, eval_accuracy = dual_stream_model.evaluate(val_ds_preprocessed)\n"
      ],
      "metadata": {
        "id": "DgvAWYPbviCb"
      },
      "id": "DgvAWYPbviCb",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple ResNet architectur test"
      ],
      "metadata": {
        "id": "xoNAxmHW6CrQ"
      },
      "id": "xoNAxmHW6CrQ"
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Pure ResNet Model Training\n",
        "from keras.backend import dropout\n",
        "class Single_ResNet(tf.keras.Model):\n",
        "    def __init__(self, n_outputs, batch_size, freeze = True, load_type=None, \n",
        "                 merge_type=\"averaging\"):\n",
        "        super().__init__()\n",
        "        self.n_outputs =  n_outputs\n",
        "        self.merge_type = merge_type\n",
        "\n",
        "        self.magno_stream = tf.keras.applications.ResNet50(\n",
        "                            include_top=False,\n",
        "                            weights= load_type,\n",
        "                            input_tensor=None,\n",
        "                            input_shape=None,\n",
        "                            pooling=None,\n",
        "                            classes=n_outputs,\n",
        "                            )\n",
        "        if freeze:\n",
        "          self.magno_stream.trainable = False\n",
        "\n",
        "        self.flat = tf.keras.layers.Flatten()\n",
        "        self.fc = Sequential([#tf.keras.layers.Dense(2048,activation='ReLU'),\n",
        "                              #tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(1280, activation='ReLU'),\n",
        "                              tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(640, activation='ReLU'),\n",
        "                              tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(self.n_outputs, activation='softmax')])\n",
        "        \n",
        "        self.avg = tf.keras.layers.Average()\n",
        "        self.concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "    def call(self,inputs):\n",
        "        color_input = inputs[:,:,:,:-1]\n",
        "\n",
        "        m_stream = self.magno_stream(color_input)\n",
        "        m_stream = self.flat(m_stream)\n",
        "\n",
        "        return self.fc(m_stream)"
      ],
      "metadata": {
        "id": "6Q0i4qDtJ1mx"
      },
      "id": "6Q0i4qDtJ1mx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FREEZE = False \n",
        "LOAD_WEIGHTS = None #One of None or imagenet\n",
        "signle_resnet_model = Single_ResNet(10,batch_size,FREEZE,load_type=LOAD_WEIGHTS,\n",
        "                                      merge_type=\"averaging\")\n",
        "signle_resnet_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "\n",
        "train_history = signle_resnet_model.fit(train_ds_preprocessed, validation_data= val_ds_preprocessed,\n",
        "                                      epochs= 30, callbacks=callback, workers = 4)\n",
        "signle_resnet_model.save(\"/content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Single_ResNet_1000_Samples_Deeper\")"
      ],
      "metadata": {
        "id": "n82_rX4HgSEg",
        "outputId": "202b614d-7f4a-4d1b-ac1e-68a97a4280ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "n82_rX4HgSEg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "291/291 [==============================] - 72s 227ms/step - loss: 13.6862 - accuracy: 0.1110 - val_loss: 2.3041 - val_accuracy: 0.1156\n",
            "Epoch 2/30\n",
            "291/291 [==============================] - 64s 219ms/step - loss: 2.2606 - accuracy: 0.1448 - val_loss: 2.2146 - val_accuracy: 0.1586\n",
            "Epoch 3/30\n",
            "291/291 [==============================] - 64s 219ms/step - loss: 2.2257 - accuracy: 0.1625 - val_loss: 2.1758 - val_accuracy: 0.1844\n",
            "Epoch 4/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 2.1793 - accuracy: 0.1795 - val_loss: 2.1855 - val_accuracy: 0.1624\n",
            "Epoch 5/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 2.1579 - accuracy: 0.1872 - val_loss: 2.0857 - val_accuracy: 0.1990\n",
            "Epoch 6/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 2.1143 - accuracy: 0.2057 - val_loss: 2.0430 - val_accuracy: 0.2119\n",
            "Epoch 7/30\n",
            "291/291 [==============================] - 64s 219ms/step - loss: 2.0276 - accuracy: 0.2475 - val_loss: 1.8438 - val_accuracy: 0.3025\n",
            "Epoch 8/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 1.8449 - accuracy: 0.3208 - val_loss: 1.7195 - val_accuracy: 0.3610\n",
            "Epoch 9/30\n",
            "291/291 [==============================] - 64s 219ms/step - loss: 1.7053 - accuracy: 0.3706 - val_loss: 1.7697 - val_accuracy: 0.3876\n",
            "Epoch 10/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 1.5818 - accuracy: 0.4107 - val_loss: 1.6281 - val_accuracy: 0.4302\n",
            "Epoch 11/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 1.4487 - accuracy: 0.4666 - val_loss: 1.5069 - val_accuracy: 0.4968\n",
            "Epoch 12/30\n",
            "291/291 [==============================] - 64s 219ms/step - loss: 1.3576 - accuracy: 0.5206 - val_loss: 1.4353 - val_accuracy: 0.5131\n",
            "Epoch 13/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 1.2633 - accuracy: 0.5657 - val_loss: 1.6752 - val_accuracy: 0.4663\n",
            "Epoch 14/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 1.1621 - accuracy: 0.6034 - val_loss: 1.5462 - val_accuracy: 0.4985\n",
            "Epoch 15/30\n",
            "291/291 [==============================] - 64s 219ms/step - loss: 1.0607 - accuracy: 0.6402 - val_loss: 1.3759 - val_accuracy: 0.5496\n",
            "Epoch 16/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 0.9723 - accuracy: 0.6715 - val_loss: 1.3965 - val_accuracy: 0.5505\n",
            "Epoch 17/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 0.9068 - accuracy: 0.7002 - val_loss: 1.1815 - val_accuracy: 0.6068\n",
            "Epoch 18/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.9139 - accuracy: 0.7037 - val_loss: 1.9005 - val_accuracy: 0.4276\n",
            "Epoch 19/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.8613 - accuracy: 0.7239 - val_loss: 1.6165 - val_accuracy: 0.5488\n",
            "Epoch 20/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 0.9083 - accuracy: 0.7168 - val_loss: 0.8941 - val_accuracy: 0.7065\n",
            "Epoch 21/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.8253 - accuracy: 0.7427 - val_loss: 2.4588 - val_accuracy: 0.4031\n",
            "Epoch 22/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.7770 - accuracy: 0.7578 - val_loss: 1.5404 - val_accuracy: 0.5526\n",
            "Epoch 23/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.7173 - accuracy: 0.7754 - val_loss: 1.4024 - val_accuracy: 0.5806\n",
            "Epoch 24/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.7621 - accuracy: 0.7703 - val_loss: 2.4900 - val_accuracy: 0.4968\n",
            "Epoch 25/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.6221 - accuracy: 0.7949 - val_loss: 1.5285 - val_accuracy: 0.5698\n",
            "Epoch 26/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.6679 - accuracy: 0.7931 - val_loss: 1.4029 - val_accuracy: 0.6768\n",
            "Epoch 27/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.7229 - accuracy: 0.7907 - val_loss: 1.6352 - val_accuracy: 0.5471\n",
            "Epoch 28/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.6196 - accuracy: 0.8157 - val_loss: 5.3809 - val_accuracy: 0.5191\n",
            "Epoch 29/30\n",
            "291/291 [==============================] - 63s 216ms/step - loss: 0.5893 - accuracy: 0.8316 - val_loss: 2.4090 - val_accuracy: 0.5724\n",
            "Epoch 30/30\n",
            "291/291 [==============================] - 64s 220ms/step - loss: 0.4971 - accuracy: 0.8489 - val_loss: 1.0312 - val_accuracy: 0.7099\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.merge.Average object at 0x7fabf524acd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.merge.Concatenate object at 0x7faa38845810>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as re_lu_6_layer_call_fn, re_lu_6_layer_call_and_return_conditional_losses, re_lu_7_layer_call_fn, re_lu_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Single_ResNet_1000_Samples_Deeper/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Vision Dataset/Models/Single_ResNet_1000_Samples_Deeper/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DualStream with VGG versions (Pending)"
      ],
      "metadata": {
        "id": "tvD1k9Kg2E14"
      },
      "id": "tvD1k9Kg2E14"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DualStream EfficientNet Architecture\n",
        "(limitation: it overfits really badly on our current dataset. The literature reports overfitting when smaller training sets are given as a serious issue with EffectiveNet)"
      ],
      "metadata": {
        "id": "I4kX10nytVHV"
      },
      "id": "I4kX10nytVHV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3258579",
      "metadata": {
        "id": "a3258579"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "                                                                                \n",
        "class DualStream_ENet(tf.keras.Model):\n",
        "    def __init__(self, n_outputs, batch_size, freeze = True, load_type=None,\n",
        "                 merge_type=\"averaging\"):\n",
        "        super().__init__()\n",
        "        self.n_outputs =  n_outputs\n",
        "        self.merge_type = merge_type\n",
        "\n",
        "        self.magno_stream = tf.keras.applications.EfficientNetB0(\n",
        "                            include_top=False,\n",
        "                            weights= load_type,\n",
        "                            input_tensor=None,\n",
        "                            input_shape=None,\n",
        "                            pooling=None,\n",
        "                            classes=self.n_outputs,\n",
        "                            classifier_activation=\"softmax\",\n",
        "                            )\n",
        "        \n",
        "        self.parvo_stream = tf.keras.applications.EfficientNetB0(\n",
        "                            include_top=False,\n",
        "                            weights= load_type,\n",
        "                            input_tensor=None,\n",
        "                            input_shape=None,\n",
        "                            pooling=None,\n",
        "                            classes=self.n_outputs,\n",
        "                            classifier_activation=\"softmax\",\n",
        "                            )\n",
        "        if freeze:\n",
        "          self.magno_stream.trainable = False\n",
        "          self.parvo_stream.trainable = False\n",
        "\n",
        "        self.flat = tf.keras.layers.Flatten()\n",
        "        self.fc = Sequential([tf.keras.layers.Dense(2048,activation='ReLU'),\n",
        "                              tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(1280, activation='ReLU'),\n",
        "                              tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(640, activation='ReLU'),\n",
        "                              tf.keras.layers.Dropout(0.5),\n",
        "                              tf.keras.layers.Dense(self.n_outputs, activation='softmax')])\n",
        "        \n",
        "        self.avg = tf.keras.layers.Average()\n",
        "        self.concat = tf.keras.layers.Concatenate()\n",
        "        self.fc_out = tf.keras.layers.Dense(self.n_outputs, activation='softmax')\n",
        "\n",
        "    def call(self,inputs):\n",
        "        color_input = inputs[:,:,:,:-1]\n",
        "        # start_time = time.time()\n",
        "        gray_input = inputs[:,:,:,-1:]\n",
        "        concat_gray_input = tf.concat([gray_input,\n",
        "                                      gray_input,\n",
        "                                      gray_input],axis=-1)\n",
        "        # print(\"delta_time:\",time.time()-start_time)\n",
        "\n",
        "        m_stream = self.magno_stream(color_input)\n",
        "        m_stream = self.flat(m_stream)\n",
        "        \n",
        "        p_stream = self.parvo_stream(concat_gray_input)\n",
        "        p_stream = self.flat(p_stream)\n",
        "        \n",
        "        if self.merge_type == \"averaging\":\n",
        "          avg_outputs = self.avg([p_stream,m_stream])\n",
        "        elif self.merge_type == \"concat\":\n",
        "          avg_outputs = self.concat([p_stream,m_stream])\n",
        "        else:\n",
        "          raise \"That layer option is not available\"\n",
        "        return self.fc(avg_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FREEZE = False #One of None or imagenet\n",
        "dual_stream_model = DualStream_ENet(50,batch_size,FREEZE,load_type=\"imagenet\",\n",
        "                                    merge_type=\"averaging\")\n",
        "dual_stream_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "i9xe3HaOoISJ"
      },
      "id": "i9xe3HaOoISJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint_path = \"/content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Models//content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Models/Dualstream_with_ResNet2.0\"\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                  save_weights_only=True,\n",
        "#                                                  verbose=1)\n",
        "\n",
        "train_history = dual_stream_model.fit(train_ds_preprocessed, validation_data= val_ds_preprocessed,\n",
        "                                      epochs= 30, callbacks=callback, workers = 4)\n",
        "dual_stream_model.save(\"/content/drive/MyDrive/School/MIT Spring2022/9.60/Vision Project/Models/Dualstream_with_EfficientNet_Deeper\")"
      ],
      "metadata": {
        "id": "bd3TM4OZquYo",
        "outputId": "6b7bba78-84c2-45fa-937c-0b1cce175de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bd3TM4OZquYo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "489/489 [==============================] - 348s 671ms/step - loss: 2.9101 - accuracy: 0.3179 - val_loss: 5.7237 - val_accuracy: 0.0133\n",
            "Epoch 2/30\n",
            "489/489 [==============================] - 325s 663ms/step - loss: 2.3374 - accuracy: 0.4244 - val_loss: 19.3927 - val_accuracy: 0.0190\n",
            "Epoch 3/30\n",
            "489/489 [==============================] - 325s 663ms/step - loss: 2.2102 - accuracy: 0.4646 - val_loss: 44.7883 - val_accuracy: 0.0207\n",
            "Epoch 4/30\n",
            "489/489 [==============================] - 325s 664ms/step - loss: 2.2732 - accuracy: 0.4535 - val_loss: 13.0702 - val_accuracy: 0.0228\n",
            "Epoch 5/30\n",
            "489/489 [==============================] - 324s 662ms/step - loss: 2.1662 - accuracy: 0.4679 - val_loss: 4.0507 - val_accuracy: 0.0251\n",
            "Epoch 6/30\n",
            "489/489 [==============================] - 324s 661ms/step - loss: 2.1699 - accuracy: 0.4697 - val_loss: 136.9688 - val_accuracy: 0.0182\n",
            "Epoch 7/30\n",
            "489/489 [==============================] - 324s 662ms/step - loss: 2.3259 - accuracy: 0.4434 - val_loss: 5.0203 - val_accuracy: 0.0269\n",
            "Epoch 8/30\n",
            "489/489 [==============================] - 324s 662ms/step - loss: 2.1509 - accuracy: 0.4663 - val_loss: 4.4336 - val_accuracy: 0.0297\n",
            "Epoch 9/30\n",
            "489/489 [==============================] - 324s 661ms/step - loss: 2.1614 - accuracy: 0.4771 - val_loss: 211.7433 - val_accuracy: 0.0202\n",
            "Epoch 10/30\n",
            "489/489 [==============================] - 324s 661ms/step - loss: 2.0761 - accuracy: 0.4886 - val_loss: 6.5694 - val_accuracy: 0.0256\n",
            "Epoch 11/30\n",
            "489/489 [==============================] - 323s 659ms/step - loss: 2.2387 - accuracy: 0.4535 - val_loss: 5.1734 - val_accuracy: 0.0190\n",
            "Epoch 12/30\n",
            "489/489 [==============================] - 324s 661ms/step - loss: 2.2110 - accuracy: 0.4583 - val_loss: 3.9455 - val_accuracy: 0.0294\n",
            "Epoch 13/30\n",
            "489/489 [==============================] - 323s 661ms/step - loss: 2.1322 - accuracy: 0.4773 - val_loss: 6.6927 - val_accuracy: 0.0143\n",
            "Epoch 14/30\n",
            "489/489 [==============================] - 323s 661ms/step - loss: 2.1872 - accuracy: 0.4592 - val_loss: 5.9065 - val_accuracy: 0.0187\n",
            "Epoch 15/30\n",
            "489/489 [==============================] - 324s 661ms/step - loss: 2.2838 - accuracy: 0.4471 - val_loss: 4.5453 - val_accuracy: 0.0136\n",
            "Epoch 16/30\n",
            "489/489 [==============================] - 325s 665ms/step - loss: 2.2285 - accuracy: 0.4513 - val_loss: 4.0267 - val_accuracy: 0.0676\n",
            "Epoch 17/30\n",
            "489/489 [==============================] - 322s 658ms/step - loss: 2.2852 - accuracy: 0.4375 - val_loss: 22.4893 - val_accuracy: 0.0179\n",
            "Epoch 18/30\n",
            "489/489 [==============================] - 323s 661ms/step - loss: 2.4089 - accuracy: 0.4031 - val_loss: 6.4417 - val_accuracy: 0.0197\n",
            "Epoch 19/30\n",
            "489/489 [==============================] - 323s 660ms/step - loss: 2.3084 - accuracy: 0.4389 - val_loss: 1444.3357 - val_accuracy: 0.0179\n",
            "Epoch 20/30\n",
            "324/489 [==================>...........] - ETA: 1:44 - loss: 2.4381 - accuracy: 0.4117"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Magno_parvo_algorithms.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}